[
{"repo_name": "/scrapy/gsoc2014-integration-tests", "about": ["\n      GSoC2014 - Scrapy Integration tests project\n    "], "website_link": null, "stars": "3", "forks": "3", "watching": "5", "main_branch_info": {"commit_count": "7", "latest_commit_author": "nitinagarwal", "latest_commit_datetime": "2014-03-18T09:59:14Z", "latest_commit_message": ["\n      Created README file, added project description.\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/slybot", "about": [], "website_link": null, "stars": "223", "forks": "62", "watching": "40", "main_branch_info": {"commit_count": "197", "latest_commit_author": "pablohoffman", "latest_commit_datetime": "2015-04-27T16:58:43Z", "latest_commit_message": ["\n      RIP slybot, long live Portia!\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/pypydispatcher", "about": ["\n      A fork of ", " with PyPy support\n    "], "website_link": null, "stars": "13", "forks": "3", "watching": "10", "main_branch_info": {"commit_count": "72", "latest_commit_author": "lopuhin", "latest_commit_datetime": "2017-07-03T15:34:19Z", "latest_commit_message": ["\n      Revert \"DOC Fix travis build link\"\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/scrapy-bench-speedcenter", "about": ["\n      Codespeed for scrapy-bench\n    "], "website_link": null, "stars": "2", "forks": "2", "watching": "7", "main_branch_info": {"commit_count": "9", "latest_commit_author": "Parth-Vader", "latest_commit_datetime": "2017-07-11T17:44:51Z", "latest_commit_message": ["\n      Update README.md\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/dirbot", "about": ["\n      Scrapy project to scrape public web directories (educational) [DEPRECATED]\n    "], "website_link": null, "stars": "1,620", "forks": "1,111", "watching": "170", "main_branch_info": {"commit_count": "34", "latest_commit_author": "redapple", "latest_commit_datetime": "2017-03-30T14:10:19Z", "latest_commit_message": ["\n      Update README.rst\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/base-chromium", "about": ["\n      base component forked from Chromium source ", "\n\n    "], "website_link": null, "stars": "4", "forks": "3", "watching": "6", "main_branch_info": {"commit_count": "15,783", "latest_commit_author": "nctl144", "latest_commit_datetime": "2018-07-31T23:01:57Z", "latest_commit_message": ["\n      add license\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/scurl", "about": ["\n      Performance-focused replacement for Python urllib\n    "], "website_link": null, "stars": "18", "forks": "6", "watching": "9", "main_branch_info": {"commit_count": "606", "latest_commit_author": "lopuhin", "latest_commit_datetime": "2018-10-02T14:51:58Z", "latest_commit_message": ["\n      Merge pull request ", "#56", " from scrapy/fix_test\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/scrapely", "about": ["\n      A pure-python HTML screen-scraping library\n    "], "website_link": null, "stars": "1,788", "forks": "256", "watching": "123", "main_branch_info": {"commit_count": "205", "latest_commit_author": "ruairif", "latest_commit_datetime": "2019-11-28T10:27:42Z", "latest_commit_message": ["\n      Merge pull request ", "#119", " from marekyggdrasil/master\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/scrapy-itemloader", "about": ["\n      [Archived] Library to populate Scrapy items using XPath and CSS with a convenient API\n    "], "website_link": "https://github.com/scrapy/itemloaders", "stars": "6", "forks": "7", "watching": "8", "main_branch_info": {"commit_count": "9", "latest_commit_author": "kmike", "latest_commit_datetime": "2020-05-05T14:21:39Z", "latest_commit_message": ["\n      Update README.md\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/quotesbot", "about": ["\n      This is a sample Scrapy project for educational purposes\n    "], "website_link": "http://doc.scrapy.org/en/latest/intro/tutorial.html", "stars": "1,107", "forks": "710", "watching": "70", "main_branch_info": {"commit_count": "5", "latest_commit_author": "stummjr", "latest_commit_datetime": "2016-10-18T11:16:30Z", "latest_commit_message": ["\n      point to spidyquotes repo in readme\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/booksbot", "about": ["\n      A crawler for ", "\n\n    "], "website_link": null, "stars": "34", "forks": "823", "watching": "10", "main_branch_info": {"commit_count": "4", "latest_commit_author": "redapple", "latest_commit_datetime": "2017-01-18T13:21:11Z", "latest_commit_message": ["\n      Merge pull request ", "#1", " from scrapy/cleanup\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/loginform", "about": ["\n      Fill HTML login forms automatically\n    "], "website_link": null, "stars": "247", "forks": "71", "watching": "27", "main_branch_info": {"commit_count": "33", "latest_commit_author": "ruairif", "latest_commit_datetime": "2016-10-21T09:02:33Z", "latest_commit_message": ["\n      Merge pull request ", "#17", " from thestakeholdercompany/master\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/scrapy-bench", "about": ["\n       A CLI for benchmarking Scrapy.\n    "], "website_link": null, "stars": "27", "forks": "15", "watching": "8", "main_branch_info": {"commit_count": "101", "latest_commit_author": "lopuhin", "latest_commit_datetime": "2021-02-24T08:42:29Z", "latest_commit_message": ["\n      Merge pull request ", "#40", " from Gallaecio/csv\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/xtractmime", "about": ["\n      \n", " implementation for Python\n    "], "website_link": null, "stars": "2", "forks": "0", "watching": "10", "main_branch_info": {"commit_count": "50", "latest_commit_author": "akshaysharmajs", "latest_commit_datetime": "2021-08-24T07:06:58Z", "latest_commit_message": ["\n      Add documentation (", "#7", ")\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/scrapy", "about": ["\n      Scrapy, a fast high-level web crawling & scraping framework for Python.\n    "], "website_link": "https://scrapy.org", "stars": "43,130", "forks": "9,572", "watching": "1.8k", "main_branch_info": {"commit_count": "9,120", "latest_commit_author": "wRAR", "latest_commit_datetime": "2022-03-23T06:06:54Z", "latest_commit_message": ["\n      Merge pull request ", "#5457", " from d00399830/typo_fixes_sm\n    "]}, "release_count": "25", "latest_release": {"tag": "2.6.1", "changelog": ["Fixes a regression introduced in 2.6.0 that would unset the request method when following redirects."], "datetime": "2022-03-01T12:52:38Z"}},
{"repo_name": "/scrapy/queuelib", "about": ["\n      Collection of persistent (disk-based) and non-persistent (memory-based) queues for Python\n    "], "website_link": null, "stars": "227", "forks": "49", "watching": "20", "main_branch_info": {"commit_count": "115", "latest_commit_author": "elacuesta", "latest_commit_datetime": "2021-08-26T13:39:03Z", "latest_commit_message": ["\n      Bump version: 1.6.1 \u2192 1.6.2\n    "]}, "release_count": "3", "latest_release": {"tag": "v1.6.2", "changelog": ["Code quality release, no changes in functionality.", "\n", "Highlights:", "\n", "\n", "Added ", "python_requires>=3.5", " to ", "setup.py", "\n", "Formatted the codebase with ", "black", "\n", "Added type annotations", "\n", "Added CI checks for typing, security and linting", "\n"], "datetime": "2021-08-26T13:41:40Z"}},
{"repo_name": "/scrapy/url-chromium", "about": ["\n      url component from Chromium source code, forked from ", "\n\n    "], "website_link": null, "stars": "1", "forks": "2", "watching": "6", "main_branch_info": {"commit_count": "346", "latest_commit_author": "nctl144", "latest_commit_datetime": "2018-08-07T21:18:49Z", "latest_commit_message": ["\n      Merge pull request ", "#2", " from scrapy/update_notes\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/cssselect", "about": ["\n      CSS Selectors for Python\n    "], "website_link": "https://cssselect.readthedocs.io/", "stars": "251", "forks": "54", "watching": "22", "main_branch_info": {"commit_count": "318", "latest_commit_author": "annbgn", "latest_commit_datetime": "2021-08-18T18:45:05Z", "latest_commit_message": ["\n      add support for :has(<relative operator>) (", "#115", ")\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/scrapyd-client", "about": ["\n      Command line client for Scrapyd server\n    "], "website_link": null, "stars": "642", "forks": "133", "watching": "42", "main_branch_info": {"commit_count": "152", "latest_commit_author": "jpmckinney", "latest_commit_datetime": "2022-01-04T18:30:44Z", "latest_commit_message": ["\n      Update CHANGES.rst\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/scrapy.org", "about": ["\n      The scrapy.org website\n    "], "website_link": "https://scrapy.org", "stars": "45", "forks": "150", "watching": "16", "main_branch_info": {"commit_count": "577", "latest_commit_author": "YuriyCherniy", "latest_commit_datetime": "2022-03-17T12:31:50Z", "latest_commit_message": ["\n      Added Anaconda badge on the homepage (", "#213", ")\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/itemloaders", "about": ["\n      Library to populate items using XPath and CSS with a convenient API \n    "], "website_link": null, "stars": "30", "forks": "10", "watching": "5", "main_branch_info": {"commit_count": "389", "latest_commit_author": "peonone", "latest_commit_datetime": "2021-06-14T13:53:16Z", "latest_commit_message": ["\n      fixed add_xpath with variables (", "#48", ")\n    "]}, "release_count": null, "latest_release": {}},
{"repo_name": "/scrapy/w3lib", "about": ["\n      Python library of web-related functions\n    "], "website_link": null, "stars": "344", "forks": "92", "watching": "24", "main_branch_info": {"commit_count": "380", "latest_commit_author": "Gallaecio", "latest_commit_datetime": "2021-11-15T07:58:58Z", "latest_commit_message": ["\n      Fix the documentation build\n    "]}, "release_count": "6", "latest_release": {"tag": "v1.22.0", "changelog": ["\n", "Python 3.4 is no longer supported (issue ", "#156", ")", "\n", "w3lib.url.safe_url_string", " now supports an optional ", "quote_path", "\nparameter to disable the percent-encoding of the URL path (issue ", "#119", ")", "\n", "w3lib.url.add_or_replace_parameter", " and", "\n", "w3lib.url.add_or_replace_parameters", " no longer remove duplicate", "\nparameters from the original query string that are not being added or", "\nreplaced (issue ", "#126", ")", "\n", "w3lib.html.remove_tags", " now raises a ", "ValueError", " exception", "\ninstead of ", "AssertionError", " when using both the ", "which_ones", " and the", "\n", "keep", " parameters (issue ", "#154", ")", "\n", "Test improvements (issues ", "#143", ", ", "#146", ", ", "#148", ", ", "#149", ")", "\n", "Documentation improvements (issues ", "#140", ", ", "#144", ", ", "#145", ", ", "#151", ", ", "#152", ", ", "#153", ")", "\n", "Code cleanup (issue ", "#139", ")", "\n"], "datetime": "2020-05-13T19:36:00Z"}},
{"repo_name": "/scrapy/protego", "about": ["\n      A pure-Python robots.txt parser with support for modern conventions. \n    "], "website_link": null, "stars": "26", "forks": "18", "watching": "9", "main_branch_info": {"commit_count": "99", "latest_commit_author": "anubhavp28", "latest_commit_datetime": "2022-02-15T10:15:57Z", "latest_commit_message": ["\n      Merge pull request ", "#21", " from anubhavp28/fix_readme_content_type_and_tr\u2026\n    "]}, "release_count": "8", "latest_release": {"tag": "Protego 0.2.1", "changelog": ["\n", "Fixes incorrect readme ", "content-type", " specified in ", "setup.py", " (", "#21", ")", "\n"], "datetime": "2022-02-19T14:19:53Z"}},
{"repo_name": "/scrapy/scrapyd", "about": ["\n      A service daemon to run Scrapy spiders\n    "], "website_link": null, "stars": "2,430", "forks": "543", "watching": "87", "main_branch_info": {"commit_count": "452", "latest_commit_author": "pawelmhm", "latest_commit_datetime": "2022-02-24T06:51:01Z", "latest_commit_message": ["\n      Merge pull request ", "#432", " from mtabbasi/master\n    "]}, "release_count": "6", "latest_release": {"tag": "1.3.0", "changelog": ["Added", "\n", "\n", "support for HTTP authentication in scrapyd server", "\n", "Jobs website shortcut to cancel a job using the cancel.json webservice.", "\n", "Make project argument to listjobs.json optional,", "\nso that we can easily query for all jobs.", "\n", "Python 3.7, 3.8, 3.9, 3.10 support", "\n", "Configuration option for job storage class", "\n", "Configuration option for egg storage class", "\n", "improved HTTP headers in webservice", "\n", "improved test coverage", "\n", "\n", "Removed", "\n", "\n", "Python 2 support", "\n", "Python 3.3 support (although never officially supported)", "\n", "Python 3.4 support", "\n", "Python 3.5 support", "\n", "Pypy 2 support", "\n", "Doc for ubuntu installs, Zyte no longer maintains ubuntu repo.", "\n", "\n", "Fixed", "\n", "\n", "ScrapyD now respects Scrapy TWISTED_REACTOR setting", "\n", "replaced deprecated SafeConfigParser with ConfigParser", "\n"], "datetime": "2022-01-12T12:58:35Z"}},
{"repo_name": "/scrapy/parsel", "about": ["\n      Parsel lets you extract data from XML/HTML documents using XPath or CSS selectors\n    "], "website_link": null, "stars": "753", "forks": "121", "watching": "33", "main_branch_info": {"commit_count": "577", "latest_commit_author": "wRAR", "latest_commit_datetime": "2021-12-22T20:16:39Z", "latest_commit_message": ["\n      Add a fix for new Sybil (", "#233", ")\n    "]}, "release_count": "12", "latest_release": {"tag": "1.6.0", "changelog": ["\n", "Python 3.4 is no longer supported", "\n", "New ", "Selector.remove()", " and ", "SelectorList.remove()", " methods to remove selected elements from the parsed document tree", "\n", "Improvements to error reporting, test coverage and documentation, and code cleanup", "\n"], "datetime": "2020-05-07T21:28:33Z"}},
{"repo_name": "/scrapy/itemadapter", "about": ["\n      Common interface for data container classes\n    "], "website_link": null, "stars": "34", "forks": "5", "watching": "6", "main_branch_info": {"commit_count": "123", "latest_commit_author": "kmike", "latest_commit_datetime": "2022-03-19T18:40:49Z", "latest_commit_message": ["\n      Merge pull request ", "#61", " from scrapy/fix-repr\n    "]}, "release_count": "4", "latest_release": {"tag": "v0.5.0", "changelog": ["What's Changed", "\n", "\n", "Deprecate undocumented predicates from the ", "utils", " module by ", "@elacuesta", " in ", "#56", "\n", "Improve performance by avoiding imports inside functions by ", "@elacuesta", " in ", "#60", "\n", "\n", "Full Changelog", ": ", "v0.4.0...v0.5.0"], "datetime": "2022-03-18T20:02:58Z"}}
]